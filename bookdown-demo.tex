\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Soil Organic Carbon Mapping cookbook},
            pdfauthor={John Doe},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Soil Organic Carbon Mapping cookbook}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{John Doe}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{2017-10-20}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Copyright and bla}\label{copyright-and-bla}

\chapter{Foreword}\label{foreword}

Under the leadership of the International Technical Panel on Soils
(ITPS), members of the Global Soil Partnership (GSP) conducted a soil
carbon mapping programme, where existing data in national soil
information systems were used to develop 1 km grids of soil carbon
stocks, following a guideline with background and detailed
specifications. These grids fulfill the criteria developed for the
version 0 grids of Global Soil Information System (GLOSIS) under Pillar
4 of the GSP.

This cookbook provides step-by-step guidance for developing 1 km grids
for soil carbon stocks. It includes the preparation of local soil data,
the compilation and pre-processing of ancillary spatial data sets,
upscaling methodologies, and uncertainty assessments. Guidance is mainly
specific to soil carbon data, but also contains many generic sections on
soil grid development, as it is relevant for other soil properties.

Therefore, this first edition is the beginning of a series of updates
and extensions, necessary to cover a larger variety of upscaling
approaches. Experiences gained throughout 2017 during the GSOC map
programme, through applications at country scale and various trainings
scheduled for 2017, shall be considered in the next editions. Also, the
section on uncertainties will be adjusted to more practical
implementation steps.

\section{Editors}\label{editors}

\begin{itemize}
\tightlist
\item
  Yusuf Yigini, Rainer Baritz, Ronald R. Vargas Global Soil Partnership,
  Food and Agriculture Organization of the United Nations
\end{itemize}

\section{Authors}\label{authors}

\begin{itemize}
\tightlist
\item
  Dick Brus - Department of Plant Sciences, Wageningen University, the
  Netherlands
\item
  Tomislav Hengl - ISRIC - World Soil Information, Wageningen, the
  Netherlands
\item
  Gerard Heuvelink - World Soil Information, Wageningen, the Netherlands
\item
  Bas Kempen - ISRIC, World Soil Information, Wageningen, the
  Netherlands
\item
  Titia VL Mulder - Wageningen University, Department of Environmental
  Sciences, The Netherlands
\item
  Guillermo Federico Olmedo - INTA, Instituto Nacional de Tecnología
  Agropecuaria, Argentina
\item
  Laura Poggio - The James Hutton Institute, Craigiebuckler Aberdeen,
  Scotland UK
\item
  Eloi Ribeiro - ISRIC , World Soil Information, Wageningen, the
  Netherlands
\item
  Christian Thine Omuto - Department of Environmental and Biosystems
  Engineering, University of Nairobi, Kenya
\end{itemize}

\chapter{Presentation}\label{presentation}

The Global Soil Partnership (GSP) aims to promote sustainable soil
management at all levels and in all land uses through normative tools
that rely on evidencebased science. Understanding the status of a given
soil, including its properties and functions, and relating this
information to the ecosystem services that soil provides becomes a
mandatory action before making decisions on how to manage a soil
sustainably. To achieve this, the availability of and use of soil data
and information is fundamental to underpin soil management decisions.
For this reason, members of the GSP have decided to establish a Global
Soil Information System (GLOSIS) that relies on national soil
information systems.

In the process of establishing GLOSIS, a number of tools and networks
are being created, including the International Network of Soil
Information Institutions (INSII), a soil data policy and more. Taking
advantage of this process and responding to a request for support in
developing the Sustainable Development Goal Indicators, especially
Indicator 15.3, the GSP Plenary Assembly instructed the
Intergovernmental Technical Panel on Soils and the GSP Secretariat to
develop a Global Soil Organic Carbon Map (GSOCMap) following the same
bottom-up approach as GLOSIS. To this end, members under the INSII
umbrella developed guidelines and technical specifications for the
preparation of the \href{http://www.fao.org/3/a-bp164e.pdf}{GSOCMap} and
countries were invited to prepare their national soil organic carbon
maps according to these specifications.

Given the scientific advances in tools for mapping soil organic carbon
(SOC), many countries requested the GSP Secretariat to support them in
the process of preparing these national maps. An intensive capacity
development programme on SOC carbon mapping was the answer to support
countries in this process. Various regional and national training
sessions were organized using an on-the-job-training modality to ensure
that national experts were trained using their own datasets. To support
this capacity development process, a reference knowledge source was
needed, hence the GSP Secretariat invited a group of top experts to
prepare a Soil Organic Carbon Mapping Cookbook.

This cookbook provides generic methodologies and the technical steps to
produce a SOC map. This includes step-by-step guidance for developing 1
km grids for SOC stocks, as well as for the preparation of local soil
data, the compilation and preprocessing of ancillary spatial data sets,
upscaling methodologies, and uncertainty assessments. Guidance is mainly
specific to soil carbon data, but also contains many generic sections on
soil grid development due to its relevance for other soil properties.

The main focus of the guidance is on the upscaling of SOC stocks in the
GSOCMap and as such the cookbook supplements the ``GSP Guidelines for
sharing national data/information to compile a Global Soil Organic
Carbon (GSOC) map''. It provides technical guidelines to prepare and
evaluate spatial soil data sets to: * Determine SOC stocks from local
samples to a target depth of 30 cm; * Prepare spatial covariates for
upscaling; and * Select and apply the best suitable upscaling
methodology.

In terms of statistical upscaling methods, the use of conventional
upscaling methods using soil maps and soil profiles is still very
common, although this approach is mostly considered empirical by soil
mappers. Even though evaluations are based on polygon soil maps, the
resulting SOC maps can be rasterized to any target grid. However, a
spatially-explicit assessment of uncertainties is impossible. The use of
digital soil mapping to upscale local soil information is increasingly
applied and recommended.

This cookbook presents two approaches in detail, namely spatial
modelling using either regression or data mining analysis, combined with
geostatistics as regression kriging.

This first edition of the cookbook will be followed by a series of
updates and extensions that would be necessary to cover a larger variety
of upscaling approaches. The experiences gained throughout 2017 during
the implementation of the GSOCMap capacity development programme will be
considered in the next editions. This will especially include updates in
the section on uncertainties which will be adjusted to provide more
practical implementation steps.

It is our hope that this cookbook will fulfil its mandate of easily
enabling any user to produce a SOC or other soil property map using soil
legacy data and modern methods of digital soil mapping in contribution
to improved decision making on soil management.

\chapter{Soil property maps}\label{soil-property-maps}

\emph{R Baritz}

\section{Definitions, objectives}\label{definitions-objectives}

Soil property maps represent spatial information about soil properties
to a certain depth or for soil horizons. Conventionally, soil property
maps are generated as polygon maps, with properties from typical soil
profiles representing soil mapping units. Digital Soil Mapping (DSM)
allows more accurate spatial mapping of soil properties, including the
spatial quantification of the prediction error. The quality of such
predictions improves with increasing number of local observations
(e.g.~soil profiles) available to build prediction model. Whenever
possible, DSM is recommended.

The development of soil property maps via digital soil mapping is
spatially flexible. For different soil properties (e.g.~concentration
and stocks of nutrients in the soil, carbon, heavy metals, pH, cation
exchange capacity, physical soil properties such as particle sizes and
bulk density, etc.), various depth classes and spatial resolution can be
modelled depending on project and mapping objectives and available input
data. For GSOCmap, a 1 km grid is pursued. The same methodology and
input data can also be used to produce higher resolution soil grids.

The mapping of global soil organic carbon stocks (GSOC) will be the
first implementation of a series of other soil property grids to be
developed for GLOSIS, based on the typical GSP country-driven system.
GSOCmap will demonstrate the capacity of countries all around the globe
to compile and manage national soil information system and to utilize
and evaluate these data following agreed international specifications.
The GSP Secretariat, FAO and its regional offices, as well as the
Regional Soil Partnerships, are all challenged together with the GSP
members, especially the members of the International Network of Soil
Information Institutions INSII), to establish national capacity and soil
data infrastructures to enable soil property mapping.

\section{Generic mapping of soil grids: upscaling of plot-level
measurements and
estimates}\label{generic-mapping-of-soil-grids-upscaling-of-plot-level-measurements-and-estimates}

The following table presents an overview of different geographic
upscaling approaches, recommended to produce soil property maps, in
particular GSOCmap.

Digital soil mapping is based on the development of functions for
upscaling point data (with soil measurements) to a full spatial extent
using correlated environmental covariates, for which spatial data are
available.

\begin{quote}
DSM: concept of environmental correlation that explores the quantitative
relationship among environmental variables and soil properties and could
be used to predict the latter; multivariate prediction techniques
\end{quote}

\chapter{Preparation of local soil property
data}\label{preparation-of-local-soil-property-data}

\emph{GF Olmedo \& R Baritz}

\section{Soil profiles and soil
augers}\label{soil-profiles-and-soil-augers}

Soil profiles are complex real world entities. Soil profiles are
composed of soil layers which form soil horizons; the soil layers have
different properties and these properties are evaluated with different
methods. As we know, soil and vertical soil properties are landscape
elements and part of matter dynamics (water, nutrients, gases, habitat).
Local soil samples or soil profiles add a third dimension into the
spatial assessment of soil properties in the landscape.

Most commonly, soil are described as vertical profiles using soil pits
(sometimes also augerings, but this is less accurate). Soil profiles are
described using macro-morphological properties. These properties can be
assessed in the field without analysis by making a field inventory or
land evaluation. For additional quantitative analysis, soils are then
sampled by genetic horizon or by depth class.

Sampling of soils is the basis to obtain quantitative information.
Depending on the goal of a project, sampling can be quite diverse.
Sampling can follow the description of the soil, or can be conducted
without, for example using a spade or auger to generate a composite
sample (for a certain depth independent of the morphological features
such as soil horizons). Sampling locations can be representative for a
certain location, project, field, or mapped object, such as a soil type.

\section{Soil database}\label{soil-database}

In order to process and evaluate soil information from field
assessments, soil profile and analytical information needs to be stored
in a database. This can be a set of simple Excel Spreadsheets, or a
relational or object-oriented data base management system (Baritz et al.
2009). When working in R, SoilProfileCollections from the R `aqp'
package could be a useful tool. Tables 2.1 -- 2.3 are examples of how
soil information can be stored. The advantage of such organization is
the possibility to develop relational databases which can be easily
queried. Such a systematic approach will support the organization of
national soil information and will reduce errors in future modelling
exercises (Baritz et al. 2009).

Table 2.1 stores site-level data, which describe the location of the
soil description and/or sampling site: spatial coordinates, landscape
attributes such as slope gradient and slope form, soil class, land cover
type, rock type etc. In this table every row should hold a single soil
profile. One column, usually the first one, should be the soil profile's
unique identifier. Using the latter, soil information can be easily
linked from one table to another.

Table 2.2 stores information from the soil description, such as horizon
name, horizon thickness, organic matter content, carbonate content, soil
color, etc. The first column contains the soil profile's unique
identifier. It is important to include the upper and lower limits for
each soil layer; in case the sampling strategy deviates from soil
layers/soil horizons, the upper and lower depth of the sampling
locations should be specified if possible. This information is needed
for modelling soil properties over the soil profile.

Table 2.3 contains the results from the laboratory soil analysis and
again lists the soil profile's unique identifier. Both tables 2.2 and
2.3 could also contain data for O horizons of forests, and H horizons
for peat soils.

\section{Completeness of
measurements/estimates}\label{completeness-of-measurementsestimates}

The GSOC mapping guideline specifies which soil parameters are needed to
produce a GSOCmap. Of course, other soil properties can be evaluated and
modelled using this cookbook as well.

SOC stocks for soil horizons or targeted soil depths can be calculated
using the equations in section 8.4.3 of the ``GSP Guidelines for sharing
national data/information to compile a Global Soil Organic Carbon map''.
Carbon concentration, bulk density and stone content for a certain depth
or genetic horizon are needed to calculate the amount of carbon stored
in that depth interval/soil horizon. In many countries, legacy data from
former surveys and projects as well as from various owners and data
sources are compiled. and very often, measured bulk densities are
missing or are only available for few soil profiles, or are estimated.
Stones in the soil profile are usually only estimated, and if augers are
used for sampling, it is not assessed at all. Pedotransfer functions can
be used to fill data gaps (bulk density), and interpolation approaches
can be used to infer from measured depths to target depths.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Stones
\end{enumerate}

The estimation of stoniness is difficult and time consuming, and
therefore not carried out in many national soil inventories, or only
estimated visually in the profile. Unfortunately, if soil inventories
and sampling are done with simple pits or augers rather than standard
soil pits, stones are very often not assessed.

As a proxy, it is recommended to derive national default values from
well described soil profile pits by soil type.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Bulk density
\end{enumerate}

The amount of fine earth is one of the basic estimation parameters to
estimate SOC stocks in the mineral soil as well as in peat layers. It
depends on the volume of soil considered (depth × reference area) and
the bulk density (BD). BD expresses the soil weight per unit volume.
When determining BD, it is important to subtract stones, if any, from
the cylinder samples; if this is not done, BD is underestimated, and the
resulting SOC stocks are overestimated. Stones in the cylinders are
added to the total stone content in order to correct for the total
amount of fine earth per volume of soil in a given area.

Most of the soil profiles in national databases come from agricultural
land. Very often, BD estimates do not consider fine stones because top
soils (e.g.~plough layers) seem to be free of visible stones.

Example for Pedotransfer functions to estimate BD, based on the soil
organic matter content in percentage:

Saini (1996) \(BD = 1,62-0,06 * OM\) Drew (1973)
\(BD = 1/(0,6268 + 0,0361 * OM)\) Jeffrey (1979)
\(BD = 1.482 - 0,6786 * (log OM)\) Grigal et. al (1989)
\(BD = 0,669 + 0,941* e ^(-0,06 * OM)\) Adams (1973)
\(BD = 100/(OM/0,244 + (100-OM))/MBD\) Honeysett \& Ratkowsky (1989)\\
\(BD = 1/(0,564 + 0,0556*OM)\)

Where MDB is the Mineral particle density, assumed to be the specific
gravity of quartz, 2.65 Mg m-3. And OM is the Organic Matter Content,
estimated as \(SOC(\%) x 1.724\)

Each method is derived from a specific set of regional soils that is
regionally adapted. Selection of the proper method for a given country
shall be based on existing reviews and comparisons.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Soil carbon analysis
\end{enumerate}

Rosell et al. (2001) have closely reviewed the different SOC and SOM
estimation procedures, and have also drawn some conclusions about the
sources of errors. Determination of SOC from dry combustion methods is
least susceptible to errors.

Dry combustion by Loss on Ignition, LoI: SOC is re-calculated applying a
conversion factor: It is commonly assumed, that organic matter contains
an average of 58\% organic carbon (so-called Van Bemmelen factor 1.724;
for non-organic horizons: SOC = SOM / 1.724). For organic horizons,
conversion factor ranges from 1.9 to 2.5 (Nelson and Sommers 1982). The
inorganic carbon is not resolved, since typically, temperatures between
400 and 550°C are used.

Wet oxidation: Since wet oxidation is applied without additional
(external) heating, low temperatures of around 120° (internal heat) are
typical. Thus, the oxidation of carbon is incomplete, and a so-called
oxidation factor needs to be applied. With external heating, the
C-recovery of the method becomes improved, up to complete recovery. No
correction against the mineral carbon is needed. Wet oxidation should
typically only be applied to samples with \textless{} 5\% organic
matter.

Usually, an average of 76\% organic carbon is recovered, leading to a
standard oxidation factor or 1.33 (Lettens et al. 2005).

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Carbonates
\end{enumerate}

In case the total organic carbon is determined with temperatures
\textgreater{} 600-800°C, the proportion of mineral soil in CaCO3 has to
be subtracted in order to derive the amount of organic carbon (inorganic
carbon is also oxidized). The pH value gives the first indication
whether the sample has to be analyzed for inorganic carbon or not.

It is crucial to report in the metadata whether national SOC values
refer to total C or if the inorganic component has been considered.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Depth
\end{enumerate}

The standard depth for GSOCmap is \textbf{0 to 30 cm}. Subdivisions are
possible depending on the available data, by genetic horizon or depth
classes. The following depths are additionally considered for GSOC map
(optional): Forest floor: thickness {[}cm{]} subdivision in horizons
depending on national soil inventory method (e.g.~L, F, H) Peat:
\textgreater{} 30 , \textless{} 100 depending on national data

\section{Completeness of depth
estimate}\label{completeness-of-depth-estimate}

Soil properties are commonly collected from the field inventories (see
Table 2.2) or from sampling and analysing horizons and/or fixed depths.
Since a fixed target depth of 30 cm is required for GSOC (other depth
classes will be recommended in the future, following the GlobalSoilMap
specifications (reference)), data holders are confronted with the
following options:

\begin{itemize}
\tightlist
\item
  \textbf{Option 1}: Soil sampling has already considered this depth:
  data can be directly used for upscaling see ``Upscaling Methods''
  section)
\item
  \textbf{Option 2}: Horizons or layers/depth classes are sampled; but
  aggregation is needed over the 0-30 cm.
\item
  \textbf{Option 3}: The target depth (0-30 cm) was not completely
  covered by sampling e.g.~only the A horizon or a topsoil layer
  (e.g.~0-20 cm) has been sampled. For both options 2 and 3, additional
  processing is needed (e.g.~equal-area splines).
\end{itemize}

For both options 2 and 3, transformation is needed using e.g.~equal-area
splines. In the case of option 3, the use of equal-area splines was
first proposed by PonceHernandez et al. (1986), and later tested against
real data (Bishop et al. 1999). This technique is based on fitting
continuous depth functions for modelling the variability of soil
properties with depth. Thus, it is possible to convert soil profiles to
standard depths, but also to fill gaps. The equal-area spline function
consists of a series of local quadratic polynomials that join at 'knots'
located at the horizon boundaries thereby the mean value of each horizon
is maintained by the spline fit. They are called equal-area splines
because the area to the left of the fitted spline curve is equal to the
area to the right of the curve.

\subsection{Technical Steps (Equal area splines using
R)}\label{technical-steps-equal-area-splines-using-r}

In R environment, the easiest way to apply equal-area splines is using
the function GSIF::mpspline from the R package GSIF (Hengl 2016, see
section 4.3.2). For illustration, a sample dataset has been used (see
Chapter 5.). This function requires data stored as SoilProfileCollection
(SPC) using package aqp. Nevertheless, data in any local soil database
or in tables like the ones proposed before (Tables 2.1, 2.2 and 2.3) can
be transformed to a SPC.

The function GSIF::mpspline has several arguments. One of the arguments
is the lambda value mentioned before. The proposed default value is 0.1.
Another argument for this function is the target standard depths. The
function produces spline-estimated values at these depths. However, this
function also produces spline-estimated values at 1 cm increments.

The following technical steps require `R' and certain packages.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load aqp package}
\KeywordTok{library}\NormalTok{(aqp)}
\CommentTok{# Load GSIF package}
\KeywordTok{library}\NormalTok{(GSIF)}
\end{Highlighting}
\end{Shaded}

\chapter{Preparation of spatial
covariates}\label{preparation-of-spatial-covariates}

\emph{R. Baritz \& Y. Yigini}

\section{DEM-derived covariates}\label{dem-derived-covariates}

\subsection{DEM source data sets}\label{dem-source-data-sets}

Currently, two global level 30 m DEMs are freely available: the Shuttle
Radar Topographic Mission (SRTM) and the ASTER Global Digital Elevation
Model (GDEM). They provide topographic data at the global scale, which
are freely available for users. Both DEMs were compared by Wong et al.
(2014). Comparison against high-resolution topographic data of Light
Detection and Ranging (LiDAR) in a mountainous tropical montane
landscape showed that the SRTM (90 m) produced better topographic data
in comparison with ASTER GDEM.

\begin{quote}
\begin{itemize}
\tightlist
\item
  Recommended for national level applications: 30 m GDEM / SRTM
\item
  Recommended for global level applications: SRTM 90 m, resampled 1
  kilometre.
\end{itemize}
\end{quote}

In both cases noise and artefacts need to be filtered out. ASTER seems
to contain more large artefacts (e.g.~peaks), particularly in flat
terrain, which are very difficult to remove through filtering.

\begin{quote}
GRASS GIS or GDAL: use ``mdenoise'' module/utility to remove noise while
preserving sharp features like ridges, lines and valleys.
\end{quote}

SRTM contains many gaps (pixels with no-data). These gaps could be
filled using splines. SAGA GIS has a module called `Close Gaps with
Splines' and other similar tools for doing this.

\section{Parent material}\label{parent-material}

Parent material has a crucial impact on soil formation, soil
geochemistry and soil physics. Parent material, if not specifically
mapped by soil mappers and included in soil maps, is usually available
from Geology maps. These maps focus on rock formation, mineral
components and age, and often lack younger surface sediments (even in
quaternary maps). Parent material/rock types classified by soil mappers
considers more strongly geochemistry and rock structure. The most
commonly available approximation to parent material is certainly a
geology map. Its geochemistry has essential impact on the soil
chemistry, e.g.~cation exchange capacity, base saturation, and nutrient
stock. The rock structure determines the ability to disintegrate, which
has impact on soil physical properties, like texture, skeleton content,
permeability, and soil thickness.

National parent material and geology maps may be used. Other available
datasets and data portals are given on the ISRIC WorldGrids website
(worldgrids.org).

\begin{itemize}
\item
  OneGeology: The world geological maps are now being integrated via the
  OneGeology project which aims at producing a consistent Geological map
  of the world in approximate scale 1:1M (Jackson, 2007)
  \url{http://www.onegeology.org/}.
\item
  USGS has several data portals, e.g.~that allow browsing of the
  International Surface Geology (split into South Asia, South America,
  Iran, Gulf of Mexico, Former Soviet Union, Europe, Caribbean,
  Bangladesh, Asia Pacific, Arctic, Arabian Peninsula, Africa and
  Afghanistan) \url{https://mrdata.usgs.gov/geology/world/}.
\item
  Hartmann and Moosdorf (2012) have assembled a global, purely
  lithological database called GLiM (Global Lithological Map). GLiM
  consists of over 1.25 million digital polygons that are classified in
  three levels (a total of 42 rock-type classes).
  \url{https://www.geo.uni-hamburg.de/en/geologie/forschung/geochemie/glim.html}).
\item
  USGS jointly with ESRI has released in 2014 a Global Ecological Land
  Units map at 250 m resolution. This also includes world layer of rock
  types. This data can be downloaded from the USGS site
  (\url{http://rmgsc.cr.usgs.gov/outgoing/ecosystems/Global/}).
\end{itemize}

\section{Soil Maps}\label{soil-maps}

Soil maps play a crucial role for upscaling soil property data from
point locations. They can be the spatial layer for conventional
upscaling, they can also serve as a covariate in digital soil mapping.
Predicted soil property maps have lower quality in areas where the
covariates such as relief, geology and climate so not correlate well
with the dependent variable, here soil carbon stocks. This is especially
true for soils under groundwater or stagnic water influence. This
information is well-represented in soil maps.

FAO, IIASA, ISRIC, ISS CAS and JRC produced a gridded 1 km soil class
map (HWSD). Global HWSD-derived soil property maps can be downloaded as
geotiffs at
\url{http://worldgrids.org/doku.php/wiki:layers\#harmonized_world_soil_database_images_5_km}
(see also section 3.6).

\begin{quote}
Digitized small-scale national soil maps are the most important spatial
layer for soil property mapping. The higher its resolution, the better
soil maps contribute to high quality soil property maps - considering
that the map should cover the target area/full country coverage.
\end{quote}

\section{Land cover/Land use}\label{land-coverland-use}

Besides soil, geology and climate, land use and/or land cover data are
unarguably vital data for any statistical effort to map soil properties.
There are many of various sources of data on land cover including global
and continental products, such as GlobCover, GeoCover, Globeland30,
CORINE Land Cover.

\subsection{GlobCover (Global)}\label{globcover-global}

GlobCover is a European Space Agency (ESA) initiative which began in
2005 in partnership with JRC, EEA, FAO, UNEP, GOFC-GOLD and IGBP. The
aim of the project was to develop a service capable of delivering global
composites and land cover maps using as input observations from the 300
m MERIS sensor onboard the ENVISAT satellite mission. ESA makes
available the land cover maps, which cover 2 periods: December 2004 -
June 2006 and January - December 2009. The classification module of the
GlobCover processing chain consists in transforming the MERIS-FR
multispectral mosaics produced by the pre-processing modules into a
meaningful global land cover map. The global land cover map has been
produced in an automatic and global way and is associated with a legend
defined and documented using the UN LCCS. The GlobCover 2009 land cover
map is delivered as one global land cover map covering the entire Earth.
Its legend, which counts 22 land cover classes, has been designed to be
consistent at the global scale and therefore, it is determined by the
level of information that is available and that makes sense at this
scale (Bontemps et al., 2011). The GlobCover data can be downloaded at:
\url{http://due.esrin.esa.int/page_globcover.php}

\subsection{Landsat GeoCover (Global)}\label{landsat-geocover-global}

The Landsat GeoCover collection of global imagery was merged into
mosaics by the Earth Satellite Company (now MDA Federal). The result was
a series of tiled imagery that is easier to wield than individual
scenes, especially since they cover larger areas than the originals. The
great detail in these mosaic scenes, however, makes them large in
storage size, so the Mr.Sid file format, which includes compression
operations, was chosen for output. While GeoCover itself is available in
three epochs of 1975, 1990 and 2000, only the latter two epochs were
made into mosaics. Coverage: The GeoCover Landsat mosaics are delivered
in a Universal Transverse Mercator (UTM) / World Geodetic System 1984
(WGS84) projection. The mosaics extend north-south over 5 degrees of
latitude, and span east-west for the full width of the UTM zone. For
mosaics below 60 degrees north latitude, the width of the mosaic is the
standard UTM zone width of 6 degrees of longitude. For mosaics above 60
degrees of latitude, the UTM zone is widened to 12 degrees, centred on
the standard even-numbered UTM meridians. To insure overlap between
adjacent UTM zones, each mosaic extends for at least 50 kilometres to
the east and west, and 1 kilometre to the north and south. Pixel size:
14.25 meters (V 2000) The data is available at:
\url{ftp://ftp.glcf.umd.edu/glcf/Mosaic_Landsat/} (FTP Access)

\subsection{Globeland30 (Global)}\label{globeland30-global}

GlobeLand30, the world's first global land cover dataset at 30 m
resolution for the years 2000 and 2010, was recently released and made
publicly available by China. The National Geomatics Center of China
under the ``Global Land Cover Mapping at Finer Resolution'' project has
recently generated a global land cover map named GlobeLand30. The
dataset covers two timestamps of 2000 and 2010, primarily acquired from
Landsat TM and ETM+ sensors, which were then coupled/checked with some
local products. The data is publicly available for non-commercial
purposes at:
\url{http://www.globallandcover.com/GLC30Download/index.aspx}\\
Further reading and other global data sources:
\url{http://worldgrids.org/doku.php/wiki:land_cover_and_land_use}

\subsection{CORINE Land Cover (Europe
Only)}\label{corine-land-cover-europe-only}

The pan-European component is coordinated by the European Environment
Agency (EEA) and produces satellite image mosaics, land cover / land use
(LC/LU) information in the CORINE Land Cover data, and the High
Resolution Layers. The CORINE Land Cover is provided for 1990, 2000,
2006 and 2012. This vector-based dataset includes 44 land cover and land
use classes. The time-series also includes a land-change layer,
highlighting changes in land cover and land-use. The high-resolution
layers (HRL) are raster-based datasets (100 m, 250 m) which provide
information about different land cover characteristics and is
complementary to land-cover mapping (e.g.~CORINE) datasets. The CORINE
Land Cover Data are available at:
\url{http://www.eea.europa.eu/data-and-maps/data}

\section{Climate}\label{climate}

\subsection{WorldClim V1.4 and V2
(Global)}\label{worldclim-v1.4-and-v2-global}

WorldClim is a set of global climate layers (gridded climate data) with
a spatial resolution of about 1 km2 (10 minutes, 5 minutes, 2.5 minutes
are also available). These data can be used for mapping and spatial
modelling. The current version is Version 1.4. and a preview of Version
2 is available for testing at worldclim.org. The data can be downloaded
as generic grids or in ESRI Grid format.

The WorldClim data layers were generated by interpolation of average
monthly climate data from weather stations on a 30 arc-second resolution
grid. In V1.4, variables included are monthly total precipitation, and
monthly mean, minimum and maximum temperatures, and 19 derived
bioclimatic variables. The WorldClim precipitation data were obtained
from a network of 1,473 stations, mean temperature from 24,542 stations,
and minimum and maximum temperatures from 14,835 stations (Hijmans et
al. 2005).

The Bioclimatic parameters are: annual mean temperature, mean diurnal
range, iso-thermality, temperature seasonality, max temperature of
warmest month, minimum temperature of coldest month, temperature annual
range , mean temperature of wettest quarter, mean temperature of driest
quarter, mean temperature of warmest quarter, mean temperature of
coldest quarter, annual precipitation, precipitation of wettest month,
precipitation of driest month, precipitation seasonality (coefficient of
variation), precipitation of wettest quarter, precipitation of driest
quarter, precipitation of warmest quarter, precipitation of coldest
quarter.

WorldClim Climate Data are available at: www.worldclim.org (WorldClim
1.4 (current conditions) by www.worldclim.org; Hijmans et al., 2005.
Int. J. of Clim. 25: 1965-1978. Is licensed under a Creative Commons
Attribution-ShareAlike 4.0 International License).

\subsection{Gridded Agro-Meteorological Data in Europe
(Europe)}\label{gridded-agro-meteorological-data-in-europe-europe}

CGMS database contains meteorological parameters from weather stations
interpolated on a 25×25 km grid. Meteorological data are available on a
daily basis from 1975 to the last calendar year completed, covering the
EU Member States, neighbouring European countries.

The following parameters are available at 1 day time resolution; *
maximum air temperature (°C), * minimum air temperature (°C), * mean air
temperature (°C), * mean daily wind speed at 10m (m/s), * mean daily
vapour pressure (hPa), * sum of precipitation (mm/day), * potential
evaporation from a free water surface (mm/day), * potential
evapotranspiration from a crop canopy (mm/day), * potential evaporation
from a moist bare soil surface (mm/day), * total global radiation
(KJ/m2/day), * Snow Depth Data Access:
\url{http://agri4cast.jrc.ec.europa.eu/DataPortal/Index.aspx}

\section{GSOCMap - Data Repository (ISRIC,
2017)}\label{gsocmap---data-repository-isric-2017}

ISRIC World Soil Information has established a data repository which
contains raster layers of various biophysical earth surface properties
for each territory in the world. These layers can be used as covariates
in a digital soil mapping exercise.

\subsection{Covariates and Empty Mask}\label{covariates-and-empty-mask}

The territories and their boundaries are obtained from the Global
Administrative Unit Layers (GAUL)dataset: each folder contains three
subfolders; covs: GIS layers of various biophysical earth surface
properties mask: an `empty' grid file of the territory with territory
boundary according to GAUL. This grid to be used for the final delivery.
. soilgrids: all SoilGrids250m soil class and property layers as
available through www.soilgrids.org. Layers are aggregated to 1 km.

\subsection{Data Specifications}\label{data-specifications}

File format: GeoTiff Coordinate system: WGS84, latitude-longitude in
decimal degrees Spatial resolution: 1km

\subsection{Data Access}\label{data-access}

\url{ftp://gsp.isric2.org/} (username: gsp, password: gspisric) or
\url{ftp://85.214.253.67/} (username: gsp, password: gspisric)

LICENCE and ACKNOWLEDGEMENT \emph{The GIS layers can be freely used
under the condition that proper credit should be given to the original
data source in each publication or product derived from these layers.
Licences, data sources, data citations are indicated the data
description table.}

\section{Extending the soil property table for spatial
statistics}\label{extending-the-soil-property-table-for-spatial-statistics}

The upscaling procedures (Chapter 6) depend on the rationale that the
accumulation of local soil carbon stocks (and also other properties)
depend on parameters for which spatial data are available, such as
climate, soil type, parent material, slope, management. This information
(Covariates) must be collected first. Details are provided above. The
properties contained in the covariates can be extracted to each
georeferenced sample site and added to the soil property table (Table
3.1). This table is used for training and validation of the statistical
model for predicting the SOC stocks which subsequently can be applied to
the full spatial extent.

\section{Preparation of a soil property table for spatial
statistics}\label{preparation-of-a-soil-property-table-for-spatial-statistics}

The upscaling procedures (section 4) depend on the rationale, that the
accumulation of local soil carbon concentrations and stocks (and also
other properties) depends on influential parameters for which spatial
data are available, such as climate, soil type, parent material, slope,
management. Any parameter in the table of local soil properties, for
which a spatial layer is available, may be included in the final table.
Other covariates will be added in section 3. An example is the clay
content, which may be derived from a soil type or parent rock map.

\begin{quote}
In case this table is prepared for different depths, 0-10 cm, 10-30 cm,
and if the host institution intends to develop different spatial models
for different depths (e.g.~separate spatial prediction model for litter
and mineral soil 0-30), then the separate grids have to be added.
\end{quote}


\end{document}
